{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66dfd2f4",
   "metadata": {},
   "source": [
    "# Car Price Data Exploration\n",
    "\n",
    "This notebook explores the car price data from Le Bon Coin using Polars for efficient data processing. The data is stored in multiple CSV files in `/Users/brunobrumbrum/Documents/data/le_boncoin_13_oct_2025`.\n",
    "\n",
    "## Objectives:\n",
    "- Load and explore all CSV files from the data directory\n",
    "- Analyze data structure, quality, and patterns\n",
    "- Generate visualizations for better understanding\n",
    "- Optimize memory usage with Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e5ec1",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Imports\n",
    "\n",
    "Import necessary libraries including Polars, matplotlib, seaborn, and pathlib for data processing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafc6f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Path and file handling\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Add project root to Python path for module imports\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == \"notebooks\" else current_dir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.config import DATA_PATH, PROCESSED_DATA_PATH, MODELS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3f522",
   "metadata": {},
   "source": [
    "## 3. Read CSV Files from Data Directory\n",
    "\n",
    "Use Polars to read all CSV files from the specified directory with `infer_schema_length=0` for faster loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir = Path(os.path.join(DATA_PATH, \"le_boncoin_13_oct_2025\"))\n",
    "# Find all CSV files\n",
    "csv_files = list(data_dir.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading CSV files with Polars...\n",
      "--------------------------------------------------\n",
      "✅ DELAGE.csv: 4 rows × 35 columns\n",
      "✅ GENERAL MOTORS.csv: 71 rows × 35 columns\n",
      "✅ AUSTIN.csv: 282 rows × 35 columns\n",
      "✅ PIAGGIO.csv: 18 rows × 35 columns\n",
      "✅ MERCURY.csv: 18 rows × 35 columns\n",
      "✅ LINCOLN.csv: 39 rows × 35 columns\n",
      "✅ TRABANT.csv: 5 rows × 35 columns\n",
      "✅ DAF.csv: 8 rows × 35 columns\n",
      "✅ LAMBORGHINI.csv: 278 rows × 35 columns\n",
      "✅ BERTONE.csv: 6 rows × 35 columns\n",
      "✅ DACIA.csv: 18,670 rows × 35 columns\n",
      "✅ SUZUKI.csv: 4,668 rows × 35 columns\n",
      "✅ CASALINI.csv: 79 rows × 35 columns\n",
      "✅ OPEL.csv: 19,869 rows × 35 columns\n",
      "✅ LEAPMOTOR.csv: 146 rows × 35 columns\n",
      "✅ GENESIS.csv: 2 rows × 35 columns\n",
      "✅ ALFA ROMEO.csv: 4,539 rows × 35 columns\n",
      "✅ BYD.csv: 434 rows × 35 columns\n",
      "✅ PORSCHE.csv: 10,838 rows × 35 columns\n",
      "✅ MORGAN.csv: 143 rows × 35 columns\n",
      "✅ KIA.csv: 10,345 rows × 35 columns\n",
      "✅ BMW.csv: 48,326 rows × 35 columns\n",
      "✅ UMM.csv: 4 rows × 35 columns\n",
      "✅ HUMMER.csv: 92 rows × 35 columns\n",
      "✅ SILENCE.csv: 3 rows × 35 columns\n",
      "✅ HONGQI.csv: 1 rows × 35 columns\n",
      "✅ NISSAN.csv: 16,208 rows × 35 columns\n",
      "✅ BELLIER.csv: 25 rows × 35 columns\n",
      "✅ INFINITI.csv: 296 rows × 35 columns\n",
      "✅ PGO.csv: 24 rows × 35 columns\n",
      "✅ JAGUAR.csv: 2,886 rows × 35 columns\n",
      "✅ MAZDA.csv: 3,976 rows × 35 columns\n",
      "✅ MICROCAR.csv: 473 rows × 35 columns\n",
      "✅ MOBILIZE.csv: 11 rows × 35 columns\n",
      "✅ GURGEL.csv: 3 rows × 35 columns\n",
      "✅ MATRA.csv: 36 rows × 35 columns\n",
      "✅ JDM SIMPA.csv: 36 rows × 35 columns\n",
      "✅ VINFAST.csv: 2 rows × 35 columns\n",
      "✅ INEOS.csv: 13 rows × 35 columns\n",
      "✅ OLDSMOBILE.csv: 16 rows × 35 columns\n",
      "✅ MASERATI.csv: 954 rows × 35 columns\n",
      "✅ ROLLS-ROYCE.csv: 71 rows × 35 columns\n",
      "✅ DE TOMASO.csv: 9 rows × 35 columns\n",
      "✅ AMC.csv: 10 rows × 35 columns\n",
      "✅ CHRYSLER.csv: 617 rows × 35 columns\n",
      "✅ VENTURI.csv: 1 rows × 35 columns\n",
      "✅ FACEL VEGA.csv: 7 rows × 35 columns\n",
      "✅ SSANGYONG.csv: 211 rows × 35 columns\n",
      "✅ HONDA.csv: 2,222 rows × 35 columns\n",
      "✅ MG_MG MOTOR.csv: 3,468 rows × 35 columns\n",
      "✅ TVR.csv: 18 rows × 35 columns\n",
      "✅ GEELY.csv: 4 rows × 35 columns\n",
      "✅ FERRARI.csv: 694 rows × 35 columns\n",
      "✅ AUDI.csv: 43,577 rows × 35 columns\n",
      "✅ ISUZU.csv: 269 rows × 35 columns\n",
      "✅ MITSUBISHI.csv: 2,457 rows × 35 columns\n",
      "✅ DS.csv: 9,264 rows × 35 columns\n",
      "✅ DAIHATSU.csv: 75 rows × 35 columns\n",
      "✅ MINI.csv: 14,726 rows × 35 columns\n",
      "✅ VESPA.csv: 11 rows × 35 columns\n",
      "✅ LOTUS.csv: 311 rows × 35 columns\n",
      "✅ CITROEN.csv: 63,678 rows × 35 columns\n",
      "✅ JENSEN.csv: 4 rows × 35 columns\n",
      "✅ SUBARU.csv: 490 rows × 35 columns\n",
      "✅ DELAHAYE.csv: 7 rows × 35 columns\n",
      "✅ CATERHAM.csv: 128 rows × 35 columns\n",
      "✅ FISKER.csv: 4 rows × 35 columns\n",
      "✅ DE LOREAN.csv: 2 rows × 35 columns\n",
      "✅ LIGIER.csv: 800 rows × 35 columns\n",
      "✅ SUNBEAM.csv: 7 rows × 35 columns\n",
      "✅ VOLKSWAGEN.csv: 57,737 rows × 35 columns\n",
      "✅ MIA ELECTRIC.csv: 4 rows × 35 columns\n",
      "✅ CUPRA.csv: 3,182 rows × 35 columns\n",
      "✅ SKYWORTH.csv: 2 rows × 35 columns\n",
      "✅ NSU.csv: 6 rows × 35 columns\n",
      "✅ XPENG.csv: 76 rows × 35 columns\n",
      "✅ PONTIAC.csv: 89 rows × 35 columns\n",
      "✅ MCLAREN.csv: 87 rows × 35 columns\n",
      "✅ LAND-ROVER.csv: 7,978 rows × 35 columns\n",
      "✅ FIAT.csv: 17,734 rows × 35 columns\n",
      "✅ MICRODRIVE.csv: 6 rows × 35 columns\n",
      "✅ PANHARD.csv: 34 rows × 35 columns\n",
      "✅ SIMCA.csv: 173 rows × 35 columns\n",
      "✅ PANTHER.csv: 7 rows × 35 columns\n",
      "✅ ROVER.csv: 250 rows × 35 columns\n",
      "✅ MORRIS.csv: 7 rows × 35 columns\n",
      "✅ LANCIA.csv: 598 rows × 35 columns\n",
      "✅ MARCOS.csv: 7 rows × 35 columns\n",
      "✅ DODGE.csv: 1,157 rows × 35 columns\n",
      "✅ TOYOTA.csv: 19,736 rows × 35 columns\n",
      "✅ PEUGEOT1.csv: 110,246 rows × 35 columns\n",
      "✅ HOTCHKISS.csv: 35 rows × 35 columns\n",
      "✅ IMF.csv: 19 rows × 35 columns\n",
      "✅ ABARTH.csv: 1,194 rows × 35 columns\n",
      "✅ TESLA.csv: 2,830 rows × 35 columns\n",
      "✅ VOLVO.csv: 6,643 rows × 35 columns\n",
      "✅ STUDEBAKER.csv: 7 rows × 35 columns\n",
      "✅ LADA.csv: 126 rows × 35 columns\n",
      "✅ EXCALIBUR.csv: 15 rows × 35 columns\n",
      "✅ SMART.csv: 1,803 rows × 35 columns\n",
      "✅ SANTANA.csv: 60 rows × 35 columns\n",
      "✅ POLESTAR.csv: 4 rows × 35 columns\n",
      "✅ PLYMOUTH.csv: 24 rows × 35 columns\n",
      "✅ SAAB.csv: 310 rows × 35 columns\n",
      "✅ AUSTIN HEALEY.csv: 84 rows × 35 columns\n",
      "✅ JEEP.csv: 5,284 rows × 35 columns\n",
      "✅ HYUNDAI.csv: 10,980 rows × 35 columns\n",
      "✅ FORD.csv: 28,610 rows × 35 columns\n",
      "✅ MERCEDES-BENZ.csv: 44,071 rows × 35 columns\n",
      "✅ XEV.csv: 2 rows × 35 columns\n",
      "✅ DAEWOO.csv: 60 rows × 35 columns\n",
      "✅ LEXUS.csv: 1,732 rows × 35 columns\n",
      "✅ BLUECAR.csv: 35 rows × 35 columns\n",
      "✅ ALPINE.csv: 698 rows × 35 columns\n",
      "✅ TALBOT.csv: 48 rows × 35 columns\n",
      "✅ LYNK&CO.csv: 165 rows × 35 columns\n",
      "✅ TRIUMPH.csv: 388 rows × 35 columns\n",
      "✅ MAHINDRA.csv: 5 rows × 35 columns\n",
      "✅ DANGEL.csv: 2 rows × 35 columns\n",
      "✅ SIMPLICI.csv: 43 rows × 35 columns\n",
      "✅ MPM.csv: 5 rows × 35 columns\n",
      "✅ CHATENET.csv: 218 rows × 35 columns\n",
      "✅ RENAULT.csv: 97,196 rows × 35 columns\n",
      "✅ AUTOBIANCHI.csv: 41 rows × 35 columns\n",
      "✅ DAIMLER.csv: 54 rows × 35 columns\n",
      "✅ AIWAYS.csv: 9 rows × 35 columns\n",
      "✅ AIXAM.csv: 1,658 rows × 35 columns\n",
      "✅ SKODA.csv: 7,509 rows × 35 columns\n",
      "✅ BUICK.csv: 55 rows × 35 columns\n",
      "✅ BEIJING.csv: 1 rows × 35 columns\n",
      "✅ DATSUN.csv: 27 rows × 35 columns\n",
      "✅ MEGA.csv: 33 rows × 35 columns\n",
      "✅ CADILLAC.csv: 175 rows × 35 columns\n",
      "✅ AC.csv: 56 rows × 35 columns\n",
      "✅ AUTRE.csv: 697 rows × 35 columns\n",
      "✅ INNOCENTI.csv: 32 rows × 35 columns\n",
      "✅ AUVERLAND.csv: 6 rows × 35 columns\n",
      "✅ ALPINA.csv: 44 rows × 35 columns\n",
      "✅ SEAT.csv: 9,801 rows × 35 columns\n",
      "✅ CHEVROLET.csv: 2,683 rows × 35 columns\n",
      "✅ BENTLEY.csv: 260 rows × 35 columns\n",
      "✅ ASTON MARTIN.csv: 417 rows × 35 columns\n",
      "✅ ARO.csv: 8 rows × 35 columns\n",
      "✅ SERES.csv: 55 rows × 35 columns\n",
      "✅ LEVC.csv: 5 rows × 35 columns\n",
      "--------------------------------------------------\n",
      "📊 Total datasets loaded: 145\n",
      "📊 Total rows across all files: 732,427\n",
      "💾 Estimated memory usage: 214.79 MB\n"
     ]
    }
   ],
   "source": [
    "# Read all CSV files using Polars with fast loading\n",
    "dataframes = {}\n",
    "total_rows = 0\n",
    "\n",
    "print(\"📥 Loading CSV files with Polars...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        df = pl.read_csv(\n",
    "            file_path,\n",
    "            infer_schema_length=0,\n",
    "            #encoding=\"utf8\",\n",
    "        )\n",
    "        \n",
    "        dataframes[file_path.stem] = df\n",
    "        rows = df.height\n",
    "        cols = df.width\n",
    "        total_rows += rows\n",
    "        \n",
    "        print(f\"✅ {file_path.name}: {rows:,} rows × {cols} columns\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading {file_path.name}: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"📊 Total datasets loaded: {len(dataframes)}\")\n",
    "print(f\"📊 Total rows across all files: {total_rows:,}\")\n",
    "\n",
    "# Show memory usage\n",
    "memory_usage = sum(df.estimated_size(\"mb\") for df in dataframes.values())\n",
    "print(f\"💾 Estimated memory usage: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376316c",
   "metadata": {},
   "source": [
    "## 4. Data Schema and Structure Analysis\n",
    "\n",
    "Examine the schema, column names, data types, and structure of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0410f9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732427, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 35)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>url</th><th>first_publication_date</th><th>index_date</th><th>price</th><th>marque</th><th>modele</th><th>annee_modele</th><th>kilometrage</th><th>energie</th><th>boite_de_vitesse</th><th>nombre_de_portes</th><th>nombre_de_place_s</th><th>version_constructeur</th><th>date_de_premiere_mise_en_circulation</th><th>type_de_vehicule</th><th>couleur</th><th>crit_air</th><th>puissance_fiscale</th><th>puissance_din</th><th>permis</th><th>reference</th><th>duree_de_disponibilite_des_pieces_detachees</th><th>pays</th><th>id_region</th><th>region</th><th>id_departement</th><th>departement</th><th>ville_affichee</th><th>ville</th><th>code_postal</th><th>latitude</th><th>longitude</th><th>source</th><th>fournisseur</th><th>forme_existante</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;https://www.leboncoin.fr/ad/vo…</td><td>&quot;2025-09-01 15:37:26&quot;</td><td>&quot;2025-10-08 18:28:10&quot;</td><td>&quot;24900 €&quot;</td><td>&quot;DELAGE&quot;</td><td>&quot;D4&quot;</td><td>&quot;1960&quot;</td><td>&quot;15000 km&quot;</td><td>&quot;Essence&quot;</td><td>&quot;Manuelle&quot;</td><td>&quot;4&quot;</td><td>&quot;4&quot;</td><td>null</td><td>&quot;01/1935&quot;</td><td>&quot;Berline&quot;</td><td>&quot;Beige&quot;</td><td>null</td><td>&quot;8 Cv&quot;</td><td>null</td><td>&quot;Avec permis&quot;</td><td>null</td><td>null</td><td>&quot;FR&quot;</td><td>&quot;3&quot;</td><td>&quot;Auvergne&quot;</td><td>&quot;63&quot;</td><td>&quot;Puy-de-Dôme&quot;</td><td>&quot;Romagnat 63540 Opme&quot;</td><td>&quot;Romagnat&quot;</td><td>&quot;63540&quot;</td><td>&quot;45.70758&quot;</td><td>&quot;3.08908&quot;</td><td>&quot;city&quot;</td><td>&quot;here&quot;</td><td>&quot;True&quot;</td></tr><tr><td>&quot;https://www.leboncoin.fr/ad/vo…</td><td>&quot;2025-10-06 19:02:42&quot;</td><td>&quot;2025-10-06 19:02:42&quot;</td><td>&quot;39000 €&quot;</td><td>&quot;DELAGE&quot;</td><td>&quot;DI&quot;</td><td>&quot;1960&quot;</td><td>&quot;43000 km&quot;</td><td>&quot;Essence&quot;</td><td>&quot;Manuelle&quot;</td><td>&quot;4&quot;</td><td>&quot;6&quot;</td><td>null</td><td>&quot;01/1924&quot;</td><td>&quot;Cabriolet&quot;</td><td>null</td><td>null</td><td>&quot;11 Cv&quot;</td><td>&quot;35 Ch&quot;</td><td>&quot;Avec permis&quot;</td><td>null</td><td>null</td><td>&quot;FR&quot;</td><td>&quot;17&quot;</td><td>&quot;Nord-Pas-de-Calais&quot;</td><td>&quot;62&quot;</td><td>&quot;Pas-de-Calais&quot;</td><td>&quot;La Couture 62136&quot;</td><td>&quot;La Couture&quot;</td><td>&quot;62136&quot;</td><td>&quot;50.58426&quot;</td><td>&quot;2.70473&quot;</td><td>&quot;city&quot;</td><td>&quot;here&quot;</td><td>&quot;True&quot;</td></tr><tr><td>&quot;https://www.leboncoin.fr/ad/vo…</td><td>&quot;2025-09-30 20:16:40&quot;</td><td>&quot;2025-09-30 20:16:40&quot;</td><td>&quot;18000 €&quot;</td><td>&quot;DELAGE&quot;</td><td>&quot;DI&quot;</td><td>&quot;1960&quot;</td><td>&quot;120000 km&quot;</td><td>&quot;Essence&quot;</td><td>&quot;Manuelle&quot;</td><td>&quot;4&quot;</td><td>&quot;5&quot;</td><td>null</td><td>&quot;01/1936&quot;</td><td>&quot;Berline&quot;</td><td>&quot;Bleu&quot;</td><td>null</td><td>&quot;12 Cv&quot;</td><td>&quot;80 Ch&quot;</td><td>&quot;Avec permis&quot;</td><td>null</td><td>null</td><td>&quot;FR&quot;</td><td>&quot;17&quot;</td><td>&quot;Nord-Pas-de-Calais&quot;</td><td>&quot;59&quot;</td><td>&quot;Nord&quot;</td><td>&quot;Rousies 59131&quot;</td><td>&quot;Rousies&quot;</td><td>&quot;59131&quot;</td><td>&quot;50.27274&quot;</td><td>&quot;4.00581&quot;</td><td>&quot;city&quot;</td><td>&quot;here&quot;</td><td>&quot;True&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 35)\n",
       "┌────────────┬────────────┬────────────┬─────────┬───┬───────────┬────────┬────────────┬───────────┐\n",
       "│ url        ┆ first_publ ┆ index_date ┆ price   ┆ … ┆ longitude ┆ source ┆ fournisseu ┆ forme_exi │\n",
       "│ ---        ┆ ication_da ┆ ---        ┆ ---     ┆   ┆ ---       ┆ ---    ┆ r          ┆ stante    │\n",
       "│ str        ┆ te         ┆ str        ┆ str     ┆   ┆ str       ┆ str    ┆ ---        ┆ ---       │\n",
       "│            ┆ ---        ┆            ┆         ┆   ┆           ┆        ┆ str        ┆ str       │\n",
       "│            ┆ str        ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "╞════════════╪════════════╪════════════╪═════════╪═══╪═══════════╪════════╪════════════╪═══════════╡\n",
       "│ https://ww ┆ 2025-09-01 ┆ 2025-10-08 ┆ 24900 € ┆ … ┆ 3.08908   ┆ city   ┆ here       ┆ True      │\n",
       "│ w.leboncoi ┆ 15:37:26   ┆ 18:28:10   ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ n.fr/ad/vo ┆            ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ …          ┆            ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ https://ww ┆ 2025-10-06 ┆ 2025-10-06 ┆ 39000 € ┆ … ┆ 2.70473   ┆ city   ┆ here       ┆ True      │\n",
       "│ w.leboncoi ┆ 19:02:42   ┆ 19:02:42   ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ n.fr/ad/vo ┆            ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ …          ┆            ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ https://ww ┆ 2025-09-30 ┆ 2025-09-30 ┆ 18000 € ┆ … ┆ 4.00581   ┆ city   ┆ here       ┆ True      │\n",
       "│ w.leboncoi ┆ 20:16:40   ┆ 20:16:40   ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ n.fr/ad/vo ┆            ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "│ …          ┆            ┆            ┆         ┆   ┆           ┆        ┆            ┆           │\n",
       "└────────────┴────────────┴────────────┴─────────┴───┴───────────┴────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.concat(dataframes.values(), how=\"vertical\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75aaaf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'first_publication_date',\n",
       " 'index_date',\n",
       " 'price',\n",
       " 'marque',\n",
       " 'modele',\n",
       " 'annee_modele',\n",
       " 'kilometrage',\n",
       " 'energie',\n",
       " 'boite_de_vitesse',\n",
       " 'nombre_de_portes',\n",
       " 'nombre_de_place_s',\n",
       " 'version_constructeur',\n",
       " 'date_de_premiere_mise_en_circulation',\n",
       " 'type_de_vehicule',\n",
       " 'couleur',\n",
       " 'crit_air',\n",
       " 'puissance_fiscale',\n",
       " 'puissance_din',\n",
       " 'permis',\n",
       " 'reference',\n",
       " 'duree_de_disponibilite_des_pieces_detachees',\n",
       " 'pays',\n",
       " 'id_region',\n",
       " 'region',\n",
       " 'id_departement',\n",
       " 'departement',\n",
       " 'ville_affichee',\n",
       " 'ville',\n",
       " 'code_postal',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'source',\n",
       " 'fournisseur',\n",
       " 'forme_existante']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b7b00",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment\n",
    "\n",
    "Check for missing values, duplicates, data type inconsistencies, and other data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "quality_report = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # Basic quality metrics\n",
    "    total_cells = df.height * df.width\n",
    "    null_cells = df.null_count().sum(axis=1)[0]\n",
    "    null_percentage = (null_cells / total_cells) * 100\n",
    "    \n",
    "    duplicate_rows = df.height - df.unique().height\n",
    "    duplicate_percentage = (duplicate_rows / df.height) * 100\n",
    "    \n",
    "    # Check for completely empty columns\n",
    "    empty_columns = [col for col in df.columns if df[col].null_count()[0] == df.height]\n",
    "    \n",
    "    quality = {\n",
    "        'Dataset': name,\n",
    "        'Completeness (%)': f\"{100 - null_percentage:.1f}\",\n",
    "        'Uniqueness (%)': f\"{100 - duplicate_percentage:.1f}\",\n",
    "        'Empty Columns': len(empty_columns),\n",
    "        'Quality Score': f\"{max(0, 100 - null_percentage - duplicate_percentage):.1f}\"\n",
    "    }\n",
    "    quality_report.append(quality)\n",
    "    \n",
    "    if empty_columns:\n",
    "        print(f\"⚠️  {name} has {len(empty_columns)} completely empty columns: {empty_columns}\")\n",
    "\n",
    "# Display quality report\n",
    "quality_df = pd.DataFrame(quality_report)\n",
    "print(\"\\n📊 QUALITY REPORT:\")\n",
    "print(quality_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data inspection for potential car price columns\n",
    "print(\"🚗 CAR PRICE RELATED COLUMNS DETECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Look for price-related columns\n",
    "price_keywords = ['price', 'prix', 'cost', 'value', 'montant', 'tarif']\n",
    "car_keywords = ['car', 'auto', 'vehicle', 'voiture', 'marque', 'modele', 'model', 'brand']\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n📋 Dataset: {name}\")\n",
    "    \n",
    "    # Find potential price columns\n",
    "    price_cols = [col for col in df.columns \n",
    "                  if any(keyword in col.lower() for keyword in price_keywords)]\n",
    "    \n",
    "    # Find potential car-related columns\n",
    "    car_cols = [col for col in df.columns \n",
    "                if any(keyword in col.lower() for keyword in car_keywords)]\n",
    "    \n",
    "    if price_cols:\n",
    "        print(f\"  💰 Potential price columns: {price_cols}\")\n",
    "        # Show sample values for price columns\n",
    "        for col in price_cols[:3]:  # Limit to first 3\n",
    "            sample_values = df[col].drop_nulls().head(5).to_list()\n",
    "            print(f\"     {col} samples: {sample_values}\")\n",
    "    \n",
    "    if car_cols:\n",
    "        print(f\"  🚗 Potential car columns: {car_cols}\")\n",
    "        # Show sample values for car columns\n",
    "        for col in car_cols[:3]:  # Limit to first 3\n",
    "            sample_values = df[col].drop_nulls().head(5).to_list()\n",
    "            print(f\"     {col} samples: {sample_values}\")\n",
    "    \n",
    "    if not price_cols and not car_cols:\n",
    "        print(\"  ❓ No obvious price or car columns detected\")\n",
    "        print(f\"     All columns: {df.columns[:10]}{'...' if len(df.columns) > 10 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be7fdf",
   "metadata": {},
   "source": [
    "## 7. Visual Data Exploration\n",
    "\n",
    "Create visualizations including histograms, box plots, correlation matrices, and distribution plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset sizes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_names = list(dataframes.keys())\n",
    "dataset_sizes = [df.height for df in dataframes.values()]\n",
    "\n",
    "ax1.bar(range(len(dataset_names)), dataset_sizes, color=sns.color_palette(\"husl\", len(dataset_names)))\n",
    "ax1.set_title('Dataset Sizes (Number of Rows)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Datasets')\n",
    "ax1.set_ylabel('Number of Rows')\n",
    "ax1.set_xticks(range(len(dataset_names)))\n",
    "ax1.set_xticklabels(dataset_names, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(dataset_sizes):\n",
    "    ax1.text(i, v + max(dataset_sizes) * 0.01, f'{v:,}', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Memory usage\n",
    "memory_usage = [df.estimated_size(\"mb\") for df in dataframes.values()]\n",
    "\n",
    "ax2.bar(range(len(dataset_names)), memory_usage, color=sns.color_palette(\"viridis\", len(dataset_names)))\n",
    "ax2.set_title('Memory Usage by Dataset', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Datasets')\n",
    "ax2.set_ylabel('Memory Usage (MB)')\n",
    "ax2.set_xticks(range(len(dataset_names)))\n",
    "ax2.set_xticklabels(dataset_names, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(memory_usage):\n",
    "    ax2.text(i, v + max(memory_usage) * 0.01, f'{v:.1f}MB', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230de37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Null values percentage\n",
    "null_percentages = []\n",
    "for df in dataframes.values():\n",
    "    total_cells = df.height * df.width\n",
    "    null_cells = df.null_count().sum(axis=1)[0]\n",
    "    null_pct = (null_cells / total_cells) * 100\n",
    "    null_percentages.append(null_pct)\n",
    "\n",
    "ax1.bar(range(len(dataset_names)), null_percentages, color='salmon')\n",
    "ax1.set_title('Data Completeness by Dataset', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Datasets')\n",
    "ax1.set_ylabel('Null Values (%)')\n",
    "ax1.set_xticks(range(len(dataset_names)))\n",
    "ax1.set_xticklabels(dataset_names, rotation=45, ha='right')\n",
    "\n",
    "# Duplicate rows percentage\n",
    "duplicate_percentages = []\n",
    "for df in dataframes.values():\n",
    "    duplicate_rows = df.height - df.unique().height\n",
    "    duplicate_pct = (duplicate_rows / df.height) * 100\n",
    "    duplicate_percentages.append(duplicate_pct)\n",
    "\n",
    "ax2.bar(range(len(dataset_names)), duplicate_percentages, color='lightcoral')\n",
    "ax2.set_title('Data Uniqueness by Dataset', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Datasets')\n",
    "ax2.set_ylabel('Duplicate Rows (%)')\n",
    "ax2.set_xticks(range(len(dataset_names)))\n",
    "ax2.set_xticklabels(dataset_names, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33016499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column distribution across datasets\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Count columns per dataset\n",
    "column_counts = [df.width for df in dataframes.values()]\n",
    "\n",
    "plt.hist(column_counts, bins=min(10, len(set(column_counts))), \n",
    "         alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Column Counts Across Datasets', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Columns')\n",
    "plt.ylabel('Number of Datasets')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics\n",
    "mean_cols = np.mean(column_counts)\n",
    "median_cols = np.median(column_counts)\n",
    "plt.axvline(mean_cols, color='red', linestyle='--', label=f'Mean: {mean_cols:.1f}')\n",
    "plt.axvline(median_cols, color='green', linestyle='--', label=f'Median: {median_cols:.1f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"📊 Column Statistics:\")\n",
    "print(f\"   Mean columns per dataset: {mean_cols:.1f}\")\n",
    "print(f\"   Median columns per dataset: {median_cols:.1f}\")\n",
    "print(f\"   Min columns: {min(column_counts)}\")\n",
    "print(f\"   Max columns: {max(column_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aebfa7",
   "metadata": {},
   "source": [
    "## 8. Memory Usage Analysis\n",
    "\n",
    "Analyze memory consumption of the datasets and optimize data types if necessary using Polars' efficient memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"💾 MEMORY USAGE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_memory = 0\n",
    "memory_breakdown = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    memory_mb = df.estimated_size(\"mb\")\n",
    "    memory_per_row = (memory_mb * 1024 * 1024) / df.height  # bytes per row\n",
    "    memory_per_col = memory_mb / df.width  # MB per column\n",
    "    \n",
    "    breakdown = {\n",
    "        'Dataset': name,\n",
    "        'Rows': f\"{df.height:,}\",\n",
    "        'Columns': df.width,\n",
    "        'Memory (MB)': f\"{memory_mb:.2f}\",\n",
    "        'Bytes/Row': f\"{memory_per_row:.1f}\",\n",
    "        'MB/Column': f\"{memory_per_col:.2f}\"\n",
    "    }\n",
    "    memory_breakdown.append(breakdown)\n",
    "    total_memory += memory_mb\n",
    "\n",
    "# Display memory breakdown\n",
    "memory_df = pd.DataFrame(memory_breakdown)\n",
    "print(memory_df.to_string(index=False))\n",
    "print(f\"\\n📊 Total Memory Usage: {total_memory:.2f} MB\")\n",
    "print(f\"📊 Average Memory per Dataset: {total_memory/len(dataframes):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d919dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory optimization analysis\n",
    "print(\"\\n🚀 MEMORY OPTIMIZATION OPPORTUNITIES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze the largest dataset for optimization opportunities\n",
    "largest_df = max(dataframes.values(), key=lambda x: x.height)\n",
    "print(f\"Analyzing largest dataset: {largest_name}\")\n",
    "print(f\"Current memory usage: {largest_df.estimated_size('mb'):.2f} MB\")\n",
    "\n",
    "# Show current data types (all are likely strings due to infer_schema_length=0)\n",
    "print(\"\\nCurrent data types:\")\n",
    "dtype_counts = {}\n",
    "for dtype in largest_df.dtypes:\n",
    "    dtype_str = str(dtype)\n",
    "    dtype_counts[dtype_str] = dtype_counts.get(dtype_str, 0) + 1\n",
    "\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"  {dtype}: {count} columns\")\n",
    "\n",
    "# Sample optimization: try to infer better types for a subset\n",
    "print(\"\\n💡 Optimization suggestion:\")\n",
    "print(\"   Since infer_schema_length=0 was used, all columns are likely strings.\")\n",
    "print(\"   Consider re-reading with infer_schema_length=None for better type inference.\")\n",
    "print(\"   This could significantly reduce memory usage for numeric columns.\")\n",
    "\n",
    "# Estimate potential savings\n",
    "string_columns = sum(1 for dtype in largest_df.dtypes if str(dtype) == 'String')\n",
    "if string_columns > 0:\n",
    "    print(f\"\\n📈 Potential optimization:\")\n",
    "    print(f\"   {string_columns} string columns could potentially be optimized\")\n",
    "    print(f\"   Estimated potential memory reduction: 30-70% (typical for mixed data types)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"📋 EXPLORATION SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"📊 Data Overview:\")\n",
    "print(f\"   • Total datasets: {len(dataframes)}\")\n",
    "print(f\"   • Total rows: {sum(df.height for df in dataframes.values()):,}\")\n",
    "print(f\"   • Total memory: {sum(df.estimated_size('mb') for df in dataframes.values()):.2f} MB\")\n",
    "\n",
    "print(f\"\\n🔍 Data Quality:\")\n",
    "avg_completeness = 100 - np.mean([\n",
    "    (df.null_count().sum(axis=1)[0] / (df.height * df.width)) * 100 \n",
    "    for df in dataframes.values()\n",
    "])\n",
    "print(f\"   • Average data completeness: {avg_completeness:.1f}%\")\n",
    "\n",
    "total_duplicates = sum(df.height - df.unique().height for df in dataframes.values())\n",
    "print(f\"   • Total duplicate rows: {total_duplicates:,}\")\n",
    "\n",
    "print(f\"\\n💡 Next Steps:\")\n",
    "print(f\"   1. Re-read data with proper schema inference for better performance\")\n",
    "print(f\"   2. Identify and clean duplicate records\")\n",
    "print(f\"   3. Handle missing values based on business requirements\")\n",
    "print(f\"   4. Merge datasets on common columns if needed\")\n",
    "print(f\"   5. Feature engineering for car price prediction\")\n",
    "\n",
    "print(f\"\\n✅ Exploration completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
